{
  "history": "Example JSON file for ice optimisation. Copy and adjust for your needs and update the history",
  "svnInfo": "Revision: $Revision$ URL: $URL: https://svn.ecdf.ed.ac.uk/repo/geos/OptClim/trunk/Configurations/example_coupledJac.json $ Date: $Date$",
  "svnInfo_comment": "Information automatically updated by SVN -- please don't edit",
  "Developer_comment": "StudyConfig.py provides methods that work with this configuration file. Remember to change them if you change structure of this.",
  "version": 2,
  "version_comment": "Version ID",
  "Name": "iceOpt_r",
  "Name_comment": "Study Name",
  "Changes_description_params": "Added 3 parameters: defaults, ranges & start values needed. ",
  "Changes_description_obs": "Added 5 obs (4 Ice + SAT): targets, covariance matrices, scalings.",
  "Chnages_description_model": "Set run_target to 20 years and set  model config to standard control case",
  "Changes_description_alg": " Alg = DFOLS, set noise.additive_noise_level to 1.2 and  max runs to 20",
  "maxRuns": null,
  "maxRuns_comment": "Maximum number of runs",
  "baseRunID": "ir",
  "baseRunID_comment": "base for runID. Only first two characters are generally used.",
  "runTime": 50000,
  "runTime_comment": "Time in seconds for run. If null then default value will be used. Should take 12 hours ~ 44K seconds",
  "runCode": null,
  "runCode_comment": "Project code to run job under.",
  "machineName": "eddie",
  "machineName_comment": "Name of machine to submit runs to",
  "modelName": "HadCM3",
  "modelName_comment": "Name of model that is ran",
  "optimiseFunction": "DFOLS",
  "optimiseFunction_comment": "Name of optimisation function to run. null gives default",
  "fakeFunction": null,
  "fakeFunction_comment": "Name of fake function to use for testing. null gives default. Your fake fn should match your postProcess skip whick it fakes.",
  "runUpgrade_vn3": "For vn3 put all runXXX & function stuff in a runInfo block.",
  "Parameters": {
    "comment": "Information relevant to parameters.",
    "defaultParams": {
      "comment": "Default parameter values for HadAM3. null values or not set mean don't modify. Checked against wiki 11/5/17 ",
      "CT": 1e-4,
      "EACF": 0.5,
      "ENTCOEF": 3.0,
      "ICE_SIZE": 30e-6,
      "RHCRIT": 0.7,
      "VF1": 1.0,
      "CW_LAND": 2e-4,
      "CW_LAND_comment": "Seed parameter which also affects CW_SEA",
      "DYNDIFF": 12.0,
      "DYNDIFF_comment": "Seed parameter which affects DIFF_COEFF, DIFF_COEFF_Q, DIFF_EXP & DIFF_EXP_Q",
      "KAY_GWAVE": 2e4,
      "KAY_GWAVE_comment": "Seed parameter which also affects KAY_LEE_GWAVE",
      "ASYM_LAMBDA": 0.15,
      "CHARNOCK": 0.012,
      "CHARNOCK_comment": "Note this is Murphy et al, 200X and is different from that reported in Yamazaki et al, 2013",
      "G0": 10.0,
      "Z0FSEA": 1.3e-3,
      "ALPHAM": 0.5,
      "ALPHAM_comment": "Seed parameter which affects DTICE and ALPHAM",
      "OcnIceDiff": 2.5e-5,
      "OcnIceDiff_comment": "Ocean Ice diffusion constant (m^2 s^1) -- see Roach et al, 2018",
      "IceMaxConc": 0.995,
      "IceMaxConc_comment": "Maximum Ice concentration in NH. Max value in SH is max(this, 0.98) -- see Roach et al, 2018",
      "OcnIsoDiff": 1e3,
      "OcnIsoDiff_comment": "Value for Ocean Isopycnal diffusion coeffecient -- see Roach et al, 2018",
      "START_TIME": null,
      "START_TIME_comment": "Start_time as 3 to 6 element array [YYYY,MM,DD,hh,mm,mm]",
      "RUN_TARGET": null,
      "RUN_TARGET_comment": "Run target -- time as 3 to 6 element array to run for. "
    },
    "initParams": {
      "comment": "Intial values for parameters to be optimised. Set to null to use default values. Values below very close to std",
      "ALPHAM": null,
      "OcnIceDiff": null,
      "IceMaxConc": null,
      "OcnIsoDiff": null
    },
    "initScale": false,
    "initScale_comment": "If true then startParams range from 0 to 1 where 0 means min value; 1 max value.",
    "fixedParams": {
      "comment": " List of parameters and values that are fixed and not modified in optimisation. Set to null to use default values",
      "CT": null,
      "EACF": null,
      "ENTCOEF": null,
      "ICE_SIZE": null,
      "RHCRIT": null,
      "VF1": null,
      "CW_LAND": null,
      "CW_LAND_comment": "Seed parameter which also affects CW_SEA",
      "DYNDIFF": null,
      "DYNDIFF_comment": "Seed parameter which affects DIFF_COEFF, DIFF_COEFF_Q, DIFF_EXP & DIFF_EXP_Q",
      "KAY_GWAVE": null,
      "KAY_GWAVE_comment": "Seed parameter which also affects KAY_LEE_GWAVE",
      "ASYM_LAMBDA": null,
      "CHARNOCK": null,
      "CHARNOCK_comment": "Note this is Murphy et al, 200X and is different from that reported in Yamazaki et al, 2013",
      "G0": null,
      "Z0FSEA": null,
      "START_TIME": [
        0,
        0,
        12
      ],
      "START_TIME_comment": "Start_time as 3 to 6 element array [YYYY,MM,DD,hh,mm,mm]",
      "RUN_TARGET": [
        20,
        0,
        0,
        0,
        0,
        1
      ],
      "RUN_TARGET_comment": "Run target -- time as 3 to 6 element array to run for. "
    },
    "fixedScale": false,
    "fixedScale_comment": "If true then scalable fixedParams range from 0 to 1 where 0 means min value; 1 max value.",
    "minmax": {
      "comment": "Defines the minimum and maximmum ranges for the parameters. Must be defined for ALL parameters. Ocn/Ice ones comes from Table 2 of Roach et al, 2018",
      "CT": [
        5e-5,
        4e-4
      ],
      "EACF": [
        0.5,
        0.7
      ],
      "ENTCOEF": [
        0.6,
        9.0
      ],
      "ICE_SIZE": [
        2.5e-5,
        4e-5
      ],
      "RHCRIT": [
        0.6,
        0.9
      ],
      "VF1": [
        0.5,
        2.0
      ],
      "CW_LAND": [
        1e-4,
        2e-3
      ],
      "DYNDIFF": [
        6.0,
        24.0
      ],
      "KAY_GWAVE": [
        1e4,
        2e4
      ],
      "ASYM_LAMBDA": [
        0.05,
        0.5
      ],
      "CHARNOCK": [
        0.012,
        0.02
      ],
      "G0": [
        5.0,
        20.0
      ],
      "Z0FSEA": [
        2e-4,
        5e-3
      ],
      "ALPHAM": [
        0.5,
        0.65
      ],
      "OcnIceDiff": [
        2.4e-5,
        37.5e-5
      ],
      "IceMaxConc": [
        0.96,
        0.995
      ],
      "OcnIsoDiff": [
        0.75,
        1.75
      ]
    },
    "steps": {
      "comment": "Steps for perturbations -- norm around 10% of the range. Atmos as 14 param in Tett et al, 18. Ice values from inspection of Letties model files.. If not specified 10% will be used. ",
      "CT": 1e-5,
      "EACF": 0.02,
      "ENTCOEF": 0.15,
      "ICE_SIZE": 1.5e-6,
      "RHCRIT": 0.01,
      "VF1": 0.1,
      "CW_LAND": 2e-4,
      "DYNDIFF": 2.0,
      "KAY_GWAVE": 4.0e+3,
      "ASYM_LAMBDA": 0.15,
      "CHARNOCK": 3.0e-3,
      "G0": 4.0,
      "Z0FSEA": 2.0e-3,
      "ALPHAM": 0.1,
      "OcnIceDiff": 3.5e-5,
      "IceMaxConc": 0.035,
      "OcnIsoDiff": 100,
      "scale_steps": false,
      "scale_steps_comment": "If true then scale the steps."
    }
  },
  "study": {
    "comment": "Parameters that specify the study. Used by framework and not by optimisation routines",
    "ensembleSize": null,
    "ensembleSize_comment": "Ensemble size for each evaluation. Not currently used by gaussNewton",
    "referenceModelDirectory": "$OPTCLIMTOP/Configurations/xnmea",
    "referenceModelDirectory_comment": "Full path to Directory where reference model configuration exists. Default is None.",
    "covariance": {
      "comment": "Covariance matrices and operations on them. If CovObsErr and CovIntVar are *both* specified then CovTotal will be computed from them",
      "CovTotal": null,
      "CovTotal_Comment": "Name of file containing Covariance Matrix for total Error.",
      "CovTotalDiagonalise": false,
      "CovTotalDiagonalise_comment": "If true diagonalise the total covariance matrix",
      "CovIntVar": "$OPTCLIMTOP/covariance/IntCovarIce.csv",
      "CovIntVar_Comment": "Name of file containing Covariance Matrix of Internal Variability",
      "CovIntVarDiagonalise": false,
      "CovIntVarDiagonalise_comment": "If true diagonalise the internal variability covariance matrix",
      "CovObsErr": "$OPTCLIMTOP/covariance/ObsCovarIce.csv",
      "CovObsErr_Comment": "Name of file containing Covariance Matrix for Observational Error ",
      "CovObsErrDiagonalise": true,
      "CovObsErrDiagonalise_comment": "If true diagonalise the Observational Error covariance matrix"
    },
    "ObsList": [
      "Nmx",
      "Nmn",
      "Smx",
      "Smn",
      "SAT"
    ],
    "ObsList_comment": "List of Observations that Algorithm uses which should be generated by post processing of model",
    "constraintName": null,
    "constraintName_comment": "Name of constraint variable -- target value defined by targets/constraintName. "
  },
  "optimise": {
    "comment": "Parameters to control optimisation. This is used within optimisation routines AND not by framework",
    "algorithm": "DFOLS",
    "algorithm_comment": "Algorithm to be used.   See runOptimise.py for more details.",
    "dfols": {
      "growing.ndirs_initial": null,
      "growing.ndirs_initial_comment": "the number of perturbations on first iteration. If not specified then will make Nparm perturbtions",
      "rhobeg": 0.1,
      "rhobeg_comment": "Radius of parameter trust region at start. Reduced to 0.1",
      "rhoend": 0.001,
      "rhoend_comment": "Radius of parameter trust region for termination (for our purpose this is in normalised parameters)",
      "maxfun": 20,
      "maxfun_comment": "Only doing at most 20 evaluations  ",
      "scaling_within_bounds": true,
      "scaling_within_bounds_comment": "Scale internally so all in range 0 to 1",
      "namedSettings": {
        "logging.save_poisedness": false,
        "logging.save_poisedness_comment": "whether or not  to calculate geometry statistics as part of diagnostic information",
        "init.random_initial_directions": true,
        "init.random_initial_directions_comment": "If true perturb in random directions. If true perturb along co-ordinate axis.",
        "init.run_in_parallel": true,
        "init.run_in_parallel_comment": "Run initial cases in parallel",
        "noise.additive_noise_level": 1.2,
        "noise.additive_noise_level_comment": "Estimate of noise in cost function. Used in termination -- nb cost fn is sum of squares **not** sum of squares/nObs.  ",
        "logging.save_diagnostic_info": true,
        "logging.save_diagnostic_info_comment": "Save logging info",
        "logging.save_xk": true,
        "logging.save_xk_comment": "Save the full vector of trial values ",
        "noise.quit_on_noise_level": true,
        "noise.quit_on_noise_level_comment": "quit/restart if all trial evaluations are within noise level of last iteration",
        "general.check_objfun_for_overflow": false,
        "general.check_objfun_for_overflow_comment": "Presumably check that function behaves itself",
        "slow.history_for_slow": 2,
        "slow.history_for_slow_comment": "No of past successful iterations to look at to decide if slow or not",
        "slow.thresh_for_slow": 0.1,
        "slow.thresh_for_slow_comment": "Log cost function  change for slow converegence",
        "slow.max_slow_iters": 5,
        "slow.max_slow_iters_comment": "The number of itertions (once slow determined) to decide making slow progress",
        "restarts.use_restarts": true,
        "restarts.use_restarts_comment": "Restart when slow convergence or too noisy",
        "restarts.use_soft_restarts": true,
        "restarts.use_soft_restarts_comment": "Use soft restart -- reuse some existing points when  restarting",
        "restarts.soft.num_geom_steps": 3,
        "restarts.soft.num_geom_steps_comment": "How many extra runs to be done when restarting",
        "restarts.increase_npt": false,
        "restarts.increase_npt_comment": "Increase number of points when restarting",
        "restarts.increase_npt_amt_comment": "Number of points to increase by in restarts.increase_npt set when restarting",
        "restarts.max_unsuccessful_restarts": 100,
        "restarts.max_unsuccessful_restarts_comment": "Number of consecutive restarts allowed when no progress made",
        "restarts.hard.increase_ndirs_initial_amt": 1,
        "restarts.hard.increase_ndirs_initial_amt_comment": "How many points to increase by  when doing hard restart (not using any exisiting pts)",
        "restarts.max_npt": null,
        "restarts.max_npt_comment": "Maximum number of points/model evals in each restart",
        "tr_radius.gamma_dec": 0.8,
        "tr_radius.alpha1": 0.9,
        "tr_radius.alpha2": 0.95
      },
      "NamedSettings_comment": "Settings for named parameters that get passed into dfols via user_params"
    },
    "dfols_comment": "Settings for DFOLS"
  },
  "postProcess": {
    "comment": "Options to control post processing. Details depend on your post processing script.",
    "script": "$OPTCLIMTOP/um45/processUMice.py",
    "script_comment": "Full path name -- including any environment variables you might have -- to postprocessing script",
    "outputPath": "observations.json",
    "outputPath_comment": "Name of output file -- default is observations.nc",
    "dirs": {
      "opy": [
        "*"
      ],
      "apy": [
        "*"
      ]
    },
    "dirs_comment": "Directories to have ummonitor run on them. Choices are list afterwards."
  },
  "targets": {
    "comment": "Observed targets for optimisation. Values are HadISST2 values for 1870-1900 -- quite uncertain esp in SH",
    "Nmx": 17.3e12,
    "Nmn": 9.2e12,
    "Smx": 27.1e12,
    "Smn": 7.8e12,
    "SAT": 286.75
  },
  "scalings": {
    "comment": "Scalings on observables -- only defined when not 1.0",
    "lprecip_nhx": 86400.0,
    "lprecip_tropics": 86400.0,
    "lprecip_shx": 86400.0,
    "mslp_gm": 0.01,
    "mslp_nhx_dgm": 0.01,
    "mslp_tropics_dgm": 0.01,
    "ICE_comment": "Scaling to convert to million km^2",
    "Nmx": 1e-12,
    "Nmn": 1e-12,
    "Smx": 1e-12,
    "Smn": 1e-12
  },
  "simulatedObservations": {
    "comment": "simulated observations -- dummy to be used when there is a model failure and it turns out to be unfixable. Made the netflux very large and the rsr_nhx large. This means that this model has high error..",
    "Nmx": 4e+13,
    "Nmn": 2e+12,
    "Smx": 3e+13,
    "Smn": 3e+12,
    "SAT": 286.3
  },
  "standardModel": {
    "SimulatedValues": {
      "comment": "Values from xhivd -- used for display",
      "Nmx": 1.872988e+13,
      "Nmn": 6.819274e+12,
      "Smx": 2.463104e+13,
      "Smn": 4.522325e+12
    }
  }
}

